{"ast":null,"code":"var _createClass = function () {\n  function defineProperties(target, props) {\n    for (var i = 0; i < props.length; i++) {\n      var descriptor = props[i];\n      descriptor.enumerable = descriptor.enumerable || false;\n      descriptor.configurable = true;\n      if (\"value\" in descriptor) descriptor.writable = true;\n      Object.defineProperty(target, descriptor.key, descriptor);\n    }\n  }\n\n  return function (Constructor, protoProps, staticProps) {\n    if (protoProps) defineProperties(Constructor.prototype, protoProps);\n    if (staticProps) defineProperties(Constructor, staticProps);\n    return Constructor;\n  };\n}();\n\nvar _class, _class2, _temp2;\n\nfunction _toConsumableArray(arr) {\n  if (Array.isArray(arr)) {\n    for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) {\n      arr2[i] = arr[i];\n    }\n\n    return arr2;\n  } else {\n    return Array.from(arr);\n  }\n}\n\nfunction _classCallCheck(instance, Constructor) {\n  if (!(instance instanceof Constructor)) {\n    throw new TypeError(\"Cannot call a class as a function\");\n  }\n}\n\nfunction _possibleConstructorReturn(self, call) {\n  if (!self) {\n    throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");\n  }\n\n  return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self;\n}\n\nfunction _inherits(subClass, superClass) {\n  if (typeof superClass !== \"function\" && superClass !== null) {\n    throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass);\n  }\n\n  subClass.prototype = Object.create(superClass && superClass.prototype, {\n    constructor: {\n      value: subClass,\n      enumerable: false,\n      writable: true,\n      configurable: true\n    }\n  });\n  if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass;\n}\n/**\n * Created by j_bleach on 2018/8/1.\n */\n\n\nimport React, { Component } from \"react\";\nimport PropTypes from \"prop-types\";\nimport MediaRecorder from \"./MediaRecorder\";\nimport RenderCanvas from \"./RenderCanvas\";\n\nvar AudioAnalyser = MediaRecorder(_class = RenderCanvas(_class = (_temp2 = _class2 = function (_Component) {\n  _inherits(AudioAnalyser, _Component);\n\n  function AudioAnalyser() {\n    var _ref;\n\n    var _temp, _this, _ret;\n\n    _classCallCheck(this, AudioAnalyser);\n\n    for (var _len = arguments.length, args = Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    return _ret = (_temp = (_this = _possibleConstructorReturn(this, (_ref = AudioAnalyser.__proto__ || Object.getPrototypeOf(AudioAnalyser)).call.apply(_ref, [this].concat(args))), _this), _this.audioProgress = function () {\n      // var request = new XMLHttpRequest();\n      // request.open(\"GET\", this.props.audioSrc, true);\n      // request.responseType = \"arraybuffer\"; // 设置数据类型为arraybuffer\n      // request.onload = () => {\n      //     var audioData = request.response;\n      //     this.audioCtx.decodeAudioData(audioData, (buffer) => {\n      //         console.log(\"buffer\", buffer)\n      //         const AudioBufferSourceNode = this.audioCtx.createBufferSource()\n      //         this.analyser = this.audioCtx.createAnalyser();\n      //         AudioBufferSourceNode.buffer = buffer; // AudioBuffer数据赋值给buffer属性\n      //         //AudioBufferSourceNode.connect(audioCtx.destination); // 如果只是播放音频，这边就直接将AudioBufferSourceNode连接到AudioDestinationNode\n      //         AudioBufferSourceNode.connect(this.analyser);  // 实现播放后，需要将bufferSourceNode连接到AnalyserNode，才能通过AnalyserNode获取后面可视化所需的数据\n      //         AudioBufferSourceNode.loop = true;  // 循环播放，默认为false\n      //         AudioBufferSourceNode.start(0); // 开始播放音频\n      //         this.renderCurve();\n      //     });\n      // }\n      // request.send();\n      // let fr = new FileReader();\n      // fr.readAsArrayBuffer(this.props.audioBlob)\n      // fr.onload = (e) => {\n      //     this.audioCtx.decodeAudioData(e.target.result).then(data => {\n      //         console.log(\"bef\", data)\n      //         // const source = this.audioCtx.createBufferSource()\n      //         // this.analyser = this.audioCtx.createAnalyser();\n      //         // source.connect(this.analyser);\n      //         // //connect the analyser to the destination(the speaker), or we won't hear the sound\n      //         // // this.analyser.connect(this.audioCtx.destination);\n      //         // source.buffer = data;\n      //         // if (!source.start) {\n      //         //     source.start = source.noteOn //in old browsers use noteOn method\n      //         //     source.stop = source.noteOff //in old browsers use noteOff method\n      //         // }\n      //         //\n      //         // // start the source playing\n      //         // source.start(0);\n      //         // console.log(\"src\", source)\n      //\n      //\n      //     })\n      // }\n      var audio = new Audio();\n      audio.src = _this.props.audioSrc;\n\n      var source = _this.audioCtx.createMediaElementSource(audio);\n\n      source.connect(_this.analyser); // this.analyser.connect(this.audioCtx.destination);\n\n      _this.renderCurve();\n    }, _temp), _possibleConstructorReturn(_this, _ret);\n  }\n\n  _createClass(AudioAnalyser, [{\n    key: \"shouldComponentUpdate\",\n    value: function shouldComponentUpdate(nextProps) {\n      return AudioAnalyser.checkRender(this.props, nextProps, AudioAnalyser.renderProps);\n    }\n  }, {\n    key: \"componentDidUpdate\",\n    value: function componentDidUpdate(prevProps) {\n      if (this.props.status !== prevProps.status) {\n        var event = {\n          inactive: this.stopAudio,\n          recording: this.startAudio,\n          paused: this.pauseAudio\n        }[this.props.status];\n        event && event();\n      } // TODO 音频回显\n      // if (this.props.audioSrc !== prevProps.audioSrc) {\n      //     const audioId = this.props.audioSrc.substring(this.props.audioSrc.length - 6)\n      //     document.getElementById(audioId).addEventListener(\"timeupdate\", this.audioProgress)\n      //     // console.log(\"change audio src!\", audioEle)\n      // }\n\n    }\n  }, {\n    key: \"render\",\n    value: function render() {\n      var _props = this.props,\n          children = _props.children,\n          className = _props.className,\n          audioSrc = _props.audioSrc;\n      return React.createElement(\"div\", {\n        className: className\n      }, React.createElement(\"div\", null, this.renderCanvas()), children, audioSrc && React.createElement(\"div\", null, React.createElement(\"audio\", {\n        controls: true,\n        src: audioSrc,\n        id: audioSrc.substring(audioSrc.length - 6)\n      })));\n    }\n  }], [{\n    key: \"checkRender\",\n\n    /**\n     * @author j_bleach 2020/1/1\n     * @describe [\"status\", \"audioSrc\"]判断是否渲染\n     * @param props: object\n     * @param nextProps: object\n     * @param renderProps: array\n     * @return boolean\n     */\n    value: function checkRender(props, nextProps, renderProps) {\n      var keys = [].concat(_toConsumableArray(new Set(renderProps)));\n      return keys.some(function (v) {\n        return props[v] !== nextProps[v];\n      });\n    }\n  }]);\n\n  return AudioAnalyser;\n}(Component), _class2.renderProps = [\"status\", \"audioSrc\"], _temp2)) || _class) || _class;\n\nAudioAnalyser.defaultProps = {\n  status: \"\",\n  audioSrc: \"\",\n  backgroundColor: \"rgba(0, 0, 0, 1)\",\n  strokeColor: \"#ffffff\",\n  className: \"audioContainer\",\n  audioBitsPerSecond: 128000,\n  mimeType: \"audio/webm\",\n  audioType: \"audio/webm\",\n  audioOptions: {},\n  width: 500,\n  height: 100\n};\nAudioAnalyser.propTypes = {\n  status: PropTypes.string,\n  audioSrc: PropTypes.string,\n  backgroundColor: PropTypes.string,\n  strokeColor: PropTypes.string,\n  className: PropTypes.string,\n  audioBitsPerSecond: PropTypes.number,\n  audioType: PropTypes.string,\n  audioOptions: PropTypes.object,\n  width: PropTypes.number,\n  height: PropTypes.number,\n  timeslice: PropTypes.number,\n  startCallback: PropTypes.func,\n  pauseCallback: PropTypes.func,\n  stopCallback: PropTypes.func,\n  onRecordCallback: PropTypes.func\n};\nexport default AudioAnalyser;","map":{"version":3,"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;;;;;AAGA,OAAOA,KAAP,IAAeC,SAAf,QAA+B,OAA/B;AACA,OAAOC,SAAP,MAAsB,YAAtB;AACA,OAAOC,aAAP,MAA0B,iBAA1B;AACA,OAAOC,YAAP,MAAyB,gBAAzB;;IAKMC,a,GAFLF,a,UACAC,Y;;;;;;;;;;;;;;oMAuCGE,gBAAgB,YAAM;MAClB;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA,IAAMC,QAAQ,IAAIC,KAAJ,EAAd;MACAD,MAAME,GAANF,GAAYG,MAAKC,KAAL,CAAWC,QAAvBL;;MACA,IAAMM,SAASH,MAAKI,QAAL,CAAcC,wBAAd,CAAuCR,KAAvC,CAAf;;MACAM,OAAOG,OAAPH,CAAeH,MAAKO,QAApBJ,EA7CkB,CA8ClB;;MACAH,MAAKQ,WAAL;;;;;;0CApEkBC,WAAW;MAC7B,OAAOd,cAAce,WAAdf,CAA0B,KAAKM,KAA/BN,EAAsCc,SAAtCd,EAAiDA,cAAcgB,WAA/DhB,CAAP;IACH;;;uCAEkBiB,WAAW;MAC1B,IAAI,KAAKX,KAAL,CAAWY,MAAX,KAAsBD,UAAUC,MAApC,EAA4C;QACxC,IAAMC,QAAQ;UACVC,UAAU,KAAKC,SADL;UAEVC,WAAW,KAAKC,UAFN;UAGVC,QAAQ,KAAKC;QAHH,EAIZ,KAAKnB,KAAL,CAAWY,MAJC,CAAd;QAKAC,SAASA,OAATA;MACH,CARyB,CAS1B;MACA;MACA;MACA;MACA;MACA;;IACH;;;6BAqDQ;MAAA,aAGD,KAAKb,KAHJ;MAAA,IAEDoB,QAFC,UAEDA,QAFC;MAAA,IAESC,SAFT,UAESA,SAFT;MAAA,IAEoBpB,QAFpB,UAEoBA,QAFpB;MAKL,OACEZ;QAAKgC,WAAWA;MAAhB,GACIhC,iCACK,KAAKiC,YAAL,EADL,CADJ,EAIKF,QAJL,EAMQnB,YACAZ,iCACIA;QAAOkC,cAAP;QAAgBzB,KAAKG,QAArB;QAA+BuB,IAAIvB,SAASwB,SAATxB,CAAmBA,SAASyB,MAATzB,GAAkB,CAArCA;MAAnC,EADJ,CAPR,CADF;IAcH;;;;IAxGD;;;;;;;;gCAQmBD,OAAOQ,WAAWE,aAAa;MAC9C,IAAMiB,oCAAW,IAAIC,GAAJ,CAAQlB,WAAR,CAAXiB,EAAN;MACA,OAAOA,KAAKE,IAALF,CAAU;QAAA,OAAK3B,MAAM8B,CAAN9B,MAAaQ,UAAUsB,CAAVtB,CAAlB;MAAV,EAAP;IACH;;;;EAfuBlB,S,WAEjBoB,W,GAAc,CAAC,QAAD,EAAW,UAAX,C,UAHxBjB,I,OADAD,I;;AAiHDE,cAAcqC,YAAdrC,GAA6B;EACzBkB,QAAQ,EADiB;EAEzBX,UAAU,EAFe;EAGzB+B,iBAAiB,kBAHQ;EAIzBC,aAAa,SAJY;EAKzBZ,WAAW,gBALc;EAMzBa,oBAAoB,MANK;EAOzBC,UAAU,YAPe;EAQzBC,WAAW,YARc;EASzBC,cAAc,EATW;EAUzBC,OAAO,GAVkB;EAWzBC,QAAQ;AAXiB,CAA7B7C;AAaAA,cAAc8C,SAAd9C,GAA0B;EACtBkB,QAAQrB,UAAUkD,MADI;EAEtBxC,UAAUV,UAAUkD,MAFE;EAGtBT,iBAAiBzC,UAAUkD,MAHL;EAItBR,aAAa1C,UAAUkD,MAJD;EAKtBpB,WAAW9B,UAAUkD,MALC;EAMtBP,oBAAoB3C,UAAUmD,MANR;EAOtBN,WAAW7C,UAAUkD,MAPC;EAQtBJ,cAAc9C,UAAUoD,MARF;EAStBL,OAAO/C,UAAUmD,MATK;EAUtBH,QAAQhD,UAAUmD,MAVI;EAWtBE,WAAWrD,UAAUmD,MAXC;EAYtBG,eAAetD,UAAUuD,IAZH;EAatBC,eAAexD,UAAUuD,IAbH;EActBE,cAAczD,UAAUuD,IAdF;EAetBG,kBAAkB1D,UAAUuD;AAfN,CAA1BpD;AAiBA,eAAeA,aAAf","names":["React","Component","PropTypes","MediaRecorder","RenderCanvas","AudioAnalyser","audioProgress","audio","Audio","src","_this","props","audioSrc","source","audioCtx","createMediaElementSource","connect","analyser","renderCurve","nextProps","checkRender","renderProps","prevProps","status","event","inactive","stopAudio","recording","startAudio","paused","pauseAudio","children","className","renderCanvas","controls","id","substring","length","keys","Set","some","v","defaultProps","backgroundColor","strokeColor","audioBitsPerSecond","mimeType","audioType","audioOptions","width","height","propTypes","string","number","object","timeslice","startCallback","func","pauseCallback","stopCallback","onRecordCallback"],"sources":["/Users/le-taoli/emotiondetecttemp/front/emotion-detector/node_modules/react-audio-analyser/src/component/AudioAnalyser/index.js"],"sourcesContent":["/**\n * Created by j_bleach on 2018/8/1.\n */\nimport React, {Component} from \"react\";\nimport PropTypes from \"prop-types\";\nimport MediaRecorder from \"./MediaRecorder\";\nimport RenderCanvas from \"./RenderCanvas\";\n\n\n@MediaRecorder\n@RenderCanvas\nclass AudioAnalyser extends Component {\n\n    static renderProps = [\"status\", \"audioSrc\"]\n\n    /**\n     * @author j_bleach 2020/1/1\n     * @describe [\"status\", \"audioSrc\"]判断是否渲染\n     * @param props: object\n     * @param nextProps: object\n     * @param renderProps: array\n     * @return boolean\n     */\n    static checkRender(props, nextProps, renderProps) {\n        const keys = [...new Set(renderProps)]\n        return keys.some(v => props[v] !== nextProps[v])\n    }\n\n    shouldComponentUpdate(nextProps) {\n        return AudioAnalyser.checkRender(this.props, nextProps, AudioAnalyser.renderProps)\n    }\n\n    componentDidUpdate(prevProps) {\n        if (this.props.status !== prevProps.status) {\n            const event = {\n                inactive: this.stopAudio,\n                recording: this.startAudio,\n                paused: this.pauseAudio\n            }[this.props.status];\n            event && event();\n        }\n        // TODO 音频回显\n        // if (this.props.audioSrc !== prevProps.audioSrc) {\n        //     const audioId = this.props.audioSrc.substring(this.props.audioSrc.length - 6)\n        //     document.getElementById(audioId).addEventListener(\"timeupdate\", this.audioProgress)\n        //     // console.log(\"change audio src!\", audioEle)\n        // }\n    }\n\n    audioProgress = () => {\n        // var request = new XMLHttpRequest();\n        // request.open(\"GET\", this.props.audioSrc, true);\n        // request.responseType = \"arraybuffer\"; // 设置数据类型为arraybuffer\n        // request.onload = () => {\n        //     var audioData = request.response;\n        //     this.audioCtx.decodeAudioData(audioData, (buffer) => {\n        //         console.log(\"buffer\", buffer)\n        //         const AudioBufferSourceNode = this.audioCtx.createBufferSource()\n        //         this.analyser = this.audioCtx.createAnalyser();\n        //         AudioBufferSourceNode.buffer = buffer; // AudioBuffer数据赋值给buffer属性\n        //         //AudioBufferSourceNode.connect(audioCtx.destination); // 如果只是播放音频，这边就直接将AudioBufferSourceNode连接到AudioDestinationNode\n        //         AudioBufferSourceNode.connect(this.analyser);  // 实现播放后，需要将bufferSourceNode连接到AnalyserNode，才能通过AnalyserNode获取后面可视化所需的数据\n        //         AudioBufferSourceNode.loop = true;  // 循环播放，默认为false\n        //         AudioBufferSourceNode.start(0); // 开始播放音频\n        //         this.renderCurve();\n        //     });\n        // }\n        // request.send();\n        // let fr = new FileReader();\n        // fr.readAsArrayBuffer(this.props.audioBlob)\n        // fr.onload = (e) => {\n        //     this.audioCtx.decodeAudioData(e.target.result).then(data => {\n        //         console.log(\"bef\", data)\n        //         // const source = this.audioCtx.createBufferSource()\n        //         // this.analyser = this.audioCtx.createAnalyser();\n        //         // source.connect(this.analyser);\n        //         // //connect the analyser to the destination(the speaker), or we won't hear the sound\n        //         // // this.analyser.connect(this.audioCtx.destination);\n        //         // source.buffer = data;\n        //         // if (!source.start) {\n        //         //     source.start = source.noteOn //in old browsers use noteOn method\n        //         //     source.stop = source.noteOff //in old browsers use noteOff method\n        //         // }\n        //         //\n        //         // // start the source playing\n        //         // source.start(0);\n        //         // console.log(\"src\", source)\n        //\n        //\n        //     })\n        // }\n        const audio = new Audio();\n        audio.src = this.props.audioSrc;\n        const source = this.audioCtx.createMediaElementSource(audio);\n        source.connect(this.analyser);\n        // this.analyser.connect(this.audioCtx.destination);\n        this.renderCurve();\n\n    }\n\n    render() {\n        const {\n            children, className, audioSrc\n        } = this.props;\n\n        return (\n          <div className={className}>\n              <div>\n                  {this.renderCanvas()}\n              </div>\n              {children}\n              {\n                  audioSrc &&\n                  <div>\n                      <audio controls src={audioSrc} id={audioSrc.substring(audioSrc.length - 6)}/>\n                  </div>\n              }\n          </div>\n        );\n    }\n}\n\nAudioAnalyser.defaultProps = {\n    status: \"\",\n    audioSrc: \"\",\n    backgroundColor: \"rgba(0, 0, 0, 1)\",\n    strokeColor: \"#ffffff\",\n    className: \"audioContainer\",\n    audioBitsPerSecond: 128000,\n    mimeType: \"audio/webm\",\n    audioType: \"audio/webm\",\n    audioOptions: {},\n    width: 500,\n    height: 100\n};\nAudioAnalyser.propTypes = {\n    status: PropTypes.string,\n    audioSrc: PropTypes.string,\n    backgroundColor: PropTypes.string,\n    strokeColor: PropTypes.string,\n    className: PropTypes.string,\n    audioBitsPerSecond: PropTypes.number,\n    audioType: PropTypes.string,\n    audioOptions: PropTypes.object,\n    width: PropTypes.number,\n    height: PropTypes.number,\n    timeslice: PropTypes.number,\n    startCallback: PropTypes.func,\n    pauseCallback: PropTypes.func,\n    stopCallback: PropTypes.func,\n    onRecordCallback: PropTypes.func\n};\nexport default AudioAnalyser;\n\n"]},"metadata":{},"sourceType":"module"}