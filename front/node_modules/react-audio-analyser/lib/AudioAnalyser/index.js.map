{"version":3,"sources":["../../src/component/AudioAnalyser/index.js"],"names":["React","Component","PropTypes","MediaRecorder","RenderCanvas","AudioAnalyser","audioProgress","audio","Audio","src","props","audioSrc","source","audioCtx","createMediaElementSource","connect","analyser","renderCurve","nextProps","checkRender","renderProps","prevProps","status","event","inactive","stopAudio","recording","startAudio","paused","pauseAudio","children","className","renderCanvas","substring","length","keys","Set","some","v","defaultProps","backgroundColor","strokeColor","audioBitsPerSecond","mimeType","audioType","audioOptions","width","height","propTypes","string","number","object","timeslice","startCallback","func","pauseCallback","stopCallback","onRecordCallback"],"mappings":";;;;;;;;;;;;AAAA;;;AAGA,OAAOA,KAAP,IAAeC,SAAf,QAA+B,OAA/B;AACA,OAAOC,SAAP,MAAsB,YAAtB;AACA,OAAOC,aAAP,MAA0B,iBAA1B;AACA,OAAOC,YAAP,MAAyB,gBAAzB;;IAKMC,a,GAFLF,a,UACAC,Y;;;;;;;;;;;;;;wMAuCGE,a,GAAgB,YAAM;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAMC,QAAQ,IAAIC,KAAJ,EAAd;AACAD,kBAAME,GAAN,GAAY,MAAKC,KAAL,CAAWC,QAAvB;AACA,gBAAMC,SAAS,MAAKC,QAAL,CAAcC,wBAAd,CAAuCP,KAAvC,CAAf;AACAK,mBAAOG,OAAP,CAAe,MAAKC,QAApB;AACA;AACA,kBAAKC,WAAL;AAEH,S;;;;;8CAtEqBC,S,EAAW;AAC7B,mBAAOb,cAAcc,WAAd,CAA0B,KAAKT,KAA/B,EAAsCQ,SAAtC,EAAiDb,cAAce,WAA/D,CAAP;AACH;;;2CAEkBC,S,EAAW;AAC1B,gBAAI,KAAKX,KAAL,CAAWY,MAAX,KAAsBD,UAAUC,MAApC,EAA4C;AACxC,oBAAMC,QAAQ;AACVC,8BAAU,KAAKC,SADL;AAEVC,+BAAW,KAAKC,UAFN;AAGVC,4BAAQ,KAAKC;AAHH,kBAIZ,KAAKnB,KAAL,CAAWY,MAJC,CAAd;AAKAC,yBAASA,OAAT;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACH;;;iCAqDQ;AAAA,yBAGD,KAAKb,KAHJ;AAAA,gBAEDoB,QAFC,UAEDA,QAFC;AAAA,gBAESC,SAFT,UAESA,SAFT;AAAA,gBAEoBpB,QAFpB,UAEoBA,QAFpB;;;AAKL,mBACE;AAAA;AAAA,kBAAK,WAAWoB,SAAhB;AACI;AAAA;AAAA;AACK,yBAAKC,YAAL;AADL,iBADJ;AAIKF,wBAJL;AAMQnB,4BACA;AAAA;AAAA;AACI,mDAAO,cAAP,EAAgB,KAAKA,QAArB,EAA+B,IAAIA,SAASsB,SAAT,CAAmBtB,SAASuB,MAAT,GAAkB,CAArC,CAAnC;AADJ;AAPR,aADF;AAcH;;;;;AAxGD;;;;;;;;oCAQmBxB,K,EAAOQ,S,EAAWE,W,EAAa;AAC9C,gBAAMe,oCAAW,IAAIC,GAAJ,CAAQhB,WAAR,CAAX,EAAN;AACA,mBAAOe,KAAKE,IAAL,CAAU;AAAA,uBAAK3B,MAAM4B,CAAN,MAAapB,UAAUoB,CAAV,CAAlB;AAAA,aAAV,CAAP;AACH;;;;EAfuBrC,S,WAEjBmB,W,GAAc,CAAC,QAAD,EAAW,UAAX,C;;AA6GzBf,cAAckC,YAAd,GAA6B;AACzBjB,YAAQ,EADiB;AAEzBX,cAAU,EAFe;AAGzB6B,qBAAiB,kBAHQ;AAIzBC,iBAAa,SAJY;AAKzBV,eAAW,gBALc;AAMzBW,wBAAoB,MANK;AAOzBC,cAAU,YAPe;AAQzBC,eAAW,YARc;AASzBC,kBAAc,EATW;AAUzBC,WAAO,GAVkB;AAWzBC,YAAQ;AAXiB,CAA7B;AAaA1C,cAAc2C,SAAd,GAA0B;AACtB1B,YAAQpB,UAAU+C,MADI;AAEtBtC,cAAUT,UAAU+C,MAFE;AAGtBT,qBAAiBtC,UAAU+C,MAHL;AAItBR,iBAAavC,UAAU+C,MAJD;AAKtBlB,eAAW7B,UAAU+C,MALC;AAMtBP,wBAAoBxC,UAAUgD,MANR;AAOtBN,eAAW1C,UAAU+C,MAPC;AAQtBJ,kBAAc3C,UAAUiD,MARF;AAStBL,WAAO5C,UAAUgD,MATK;AAUtBH,YAAQ7C,UAAUgD,MAVI;AAWtBE,eAAWlD,UAAUgD,MAXC;AAYtBG,mBAAenD,UAAUoD,IAZH;AAatBC,mBAAerD,UAAUoD,IAbH;AActBE,kBAActD,UAAUoD,IAdF;AAetBG,sBAAkBvD,UAAUoD;AAfN,CAA1B;AAiBA,eAAejD,aAAf","file":"index.js","sourcesContent":["/**\n * Created by j_bleach on 2018/8/1.\n */\nimport React, {Component} from \"react\";\nimport PropTypes from \"prop-types\";\nimport MediaRecorder from \"./MediaRecorder\";\nimport RenderCanvas from \"./RenderCanvas\";\n\n\n@MediaRecorder\n@RenderCanvas\nclass AudioAnalyser extends Component {\n\n    static renderProps = [\"status\", \"audioSrc\"]\n\n    /**\n     * @author j_bleach 2020/1/1\n     * @describe [\"status\", \"audioSrc\"]判断是否渲染\n     * @param props: object\n     * @param nextProps: object\n     * @param renderProps: array\n     * @return boolean\n     */\n    static checkRender(props, nextProps, renderProps) {\n        const keys = [...new Set(renderProps)]\n        return keys.some(v => props[v] !== nextProps[v])\n    }\n\n    shouldComponentUpdate(nextProps) {\n        return AudioAnalyser.checkRender(this.props, nextProps, AudioAnalyser.renderProps)\n    }\n\n    componentDidUpdate(prevProps) {\n        if (this.props.status !== prevProps.status) {\n            const event = {\n                inactive: this.stopAudio,\n                recording: this.startAudio,\n                paused: this.pauseAudio\n            }[this.props.status];\n            event && event();\n        }\n        // TODO 音频回显\n        // if (this.props.audioSrc !== prevProps.audioSrc) {\n        //     const audioId = this.props.audioSrc.substring(this.props.audioSrc.length - 6)\n        //     document.getElementById(audioId).addEventListener(\"timeupdate\", this.audioProgress)\n        //     // console.log(\"change audio src!\", audioEle)\n        // }\n    }\n\n    audioProgress = () => {\n        // var request = new XMLHttpRequest();\n        // request.open(\"GET\", this.props.audioSrc, true);\n        // request.responseType = \"arraybuffer\"; // 设置数据类型为arraybuffer\n        // request.onload = () => {\n        //     var audioData = request.response;\n        //     this.audioCtx.decodeAudioData(audioData, (buffer) => {\n        //         console.log(\"buffer\", buffer)\n        //         const AudioBufferSourceNode = this.audioCtx.createBufferSource()\n        //         this.analyser = this.audioCtx.createAnalyser();\n        //         AudioBufferSourceNode.buffer = buffer; // AudioBuffer数据赋值给buffer属性\n        //         //AudioBufferSourceNode.connect(audioCtx.destination); // 如果只是播放音频，这边就直接将AudioBufferSourceNode连接到AudioDestinationNode\n        //         AudioBufferSourceNode.connect(this.analyser);  // 实现播放后，需要将bufferSourceNode连接到AnalyserNode，才能通过AnalyserNode获取后面可视化所需的数据\n        //         AudioBufferSourceNode.loop = true;  // 循环播放，默认为false\n        //         AudioBufferSourceNode.start(0); // 开始播放音频\n        //         this.renderCurve();\n        //     });\n        // }\n        // request.send();\n        // let fr = new FileReader();\n        // fr.readAsArrayBuffer(this.props.audioBlob)\n        // fr.onload = (e) => {\n        //     this.audioCtx.decodeAudioData(e.target.result).then(data => {\n        //         console.log(\"bef\", data)\n        //         // const source = this.audioCtx.createBufferSource()\n        //         // this.analyser = this.audioCtx.createAnalyser();\n        //         // source.connect(this.analyser);\n        //         // //connect the analyser to the destination(the speaker), or we won't hear the sound\n        //         // // this.analyser.connect(this.audioCtx.destination);\n        //         // source.buffer = data;\n        //         // if (!source.start) {\n        //         //     source.start = source.noteOn //in old browsers use noteOn method\n        //         //     source.stop = source.noteOff //in old browsers use noteOff method\n        //         // }\n        //         //\n        //         // // start the source playing\n        //         // source.start(0);\n        //         // console.log(\"src\", source)\n        //\n        //\n        //     })\n        // }\n        const audio = new Audio();\n        audio.src = this.props.audioSrc;\n        const source = this.audioCtx.createMediaElementSource(audio);\n        source.connect(this.analyser);\n        // this.analyser.connect(this.audioCtx.destination);\n        this.renderCurve();\n\n    }\n\n    render() {\n        const {\n            children, className, audioSrc\n        } = this.props;\n\n        return (\n          <div className={className}>\n              <div>\n                  {this.renderCanvas()}\n              </div>\n              {children}\n              {\n                  audioSrc &&\n                  <div>\n                      <audio controls src={audioSrc} id={audioSrc.substring(audioSrc.length - 6)}/>\n                  </div>\n              }\n          </div>\n        );\n    }\n}\n\nAudioAnalyser.defaultProps = {\n    status: \"\",\n    audioSrc: \"\",\n    backgroundColor: \"rgba(0, 0, 0, 1)\",\n    strokeColor: \"#ffffff\",\n    className: \"audioContainer\",\n    audioBitsPerSecond: 128000,\n    mimeType: \"audio/webm\",\n    audioType: \"audio/webm\",\n    audioOptions: {},\n    width: 500,\n    height: 100\n};\nAudioAnalyser.propTypes = {\n    status: PropTypes.string,\n    audioSrc: PropTypes.string,\n    backgroundColor: PropTypes.string,\n    strokeColor: PropTypes.string,\n    className: PropTypes.string,\n    audioBitsPerSecond: PropTypes.number,\n    audioType: PropTypes.string,\n    audioOptions: PropTypes.object,\n    width: PropTypes.number,\n    height: PropTypes.number,\n    timeslice: PropTypes.number,\n    startCallback: PropTypes.func,\n    pauseCallback: PropTypes.func,\n    stopCallback: PropTypes.func,\n    onRecordCallback: PropTypes.func\n};\nexport default AudioAnalyser;\n\n"]}